###############################################################################################
#  
#  Created by: Jonathan Tan (jona1115@iastate.edu)
#  Date      : 1/29/2024
#  
###########################################################################################
#  
#  PerfOutputFileParser.py: This class is used to parse the txt output file generated by
#                           perf.
#  
#  Revision 1 (x/x/xxxx):
#  
###############################################################################################

# Library imports
from loguru import logger
import csv

# Project imports


# Start of code
class PerfOutputFileParser:
    # Constructor
    def __init__(self, givenInputFilePath, givenOutputPath):
        """
        givenFilePath, and givenOutputPath should be the path + the file name.
        Eg. /home/jonathan/example.csv
        """
        self.inputPath = givenInputFilePath
        self.outputPath = givenOutputPath

        if not self.checkThatFileLooksGood():
            logger.error("There is an issue with the outputted perf file!")
            return None
        self.removeTitleLines()
        self.parse_to_csv()
    
    ######################## Methods ########################
    def checkThatFileLooksGood(self):
        """
        This function make sure that the outputted file looks good. It returns True if good, False if 
        there's some issues with the file.

        Important:
        This function should run BEFORE removeTitleLines()
        
        Things it check
        1. It make sure the first line is "#           time             counts unit events"
        """
        TITLE_LINE = "#           time             counts unit events\n"
        
        with open(self.inputPath, 'r') as file:
            lines = file.readlines()
            if lines[0] != TITLE_LINE:
                return False
            
        return True
    
    def removeTitleLines(self):
        """
        This function removes the title lines generated by perf.

        This method/function is partially written by, or written with the aid of, ChatGPT.
        """
        with open(self.inputPath, 'r') as file:
            lines = file.readlines()

        LINE_WE_DONT_WANT = "#           time             counts unit events\n"
        with open(self.inputPath, 'w') as file:
            for line in lines:
                if LINE_WE_DONT_WANT not in line:
                    file.write(line)

    def parse_to_csv(self):
        """
        This function is O(my 311 professor wont like it) xD

        Idea:
        1. We want to find how many different events are in the file, this is done by 
           looping through the first x lines until we see a repeated event, then we know
           we found all.
        2. We collect data of all types, sorting them basically using a list.
        3. We generate output (also add the title lines back)
        """
        
        found_all_events = False
        type_of_events_list = []
        events_history_2d = []
        
        # Step 1
        with open(self.inputPath, 'r') as infile:
            for line in infile:
                line = line.strip()

                if line and (not found_all_events):
                    parts = line.split()
                    event = ""
                    if parts[1] == "<not":  # This happens when perf return "<not counted>" for the counter value for some reason
                        # Perf isnt good
                        event = parts[3]
                    else:
                        # Perf is good
                        event = parts[2]

                    if event not in type_of_events_list:
                        type_of_events_list.append(event)
                    else:
                        found_all_events = True

                        # Create empty child list in events_history_2d
                        for _ in range(len(type_of_events_list)):
                            events_history_2d.append([])
                        
                        break

        # Step 2
        with open(self.inputPath, 'r') as infile:
            for line in infile:
                line = line.strip()
                if line and found_all_events:
                    parts = line.split()
                    time = parts[0]
                    time = format(float(time), '.1f')  # Format the time so it is only one decimal point
                    count = 0
                    event = ""
                    try:
                        if parts[1] == "<not":  # This happens when perf return "<not counted>" for the counter value for some reason
                            # Perf isnt good
                            count = -1 # -1 == No count
                            event = parts[3]
                        else:
                            # Perf is good
                            count = parts[1].replace(',', '')  # Remove commas
                            event = parts[2]
                    except IndexError as e:
                        logger.error(f"IndexError occured: {e}")

                    try:                    
                        index_of_curr_event = type_of_events_list.index(event)
                    except ValueError as e:
                        logger.error(f"ValueError occured: {e}")
                        logger.debug(f"List: {type_of_events_list}")

                    if not (index_of_curr_event > len(type_of_events_list)):
                        curr_event_time_count = (time, count)
                        events_history_2d[index_of_curr_event].append(curr_event_time_count)
                    else:
                        # This should never happen
                        logger.error("Something terrible had happened.")
                    
                    # logger.debug(f"\ntime: {time}\ncount: {count}\nevent: {event}")

        # Step 3
        with open(self.outputPath, 'w', newline='') as outfile:
            # Get all the title field names
            fieldnames = ["Time"]
            for i in range(len(type_of_events_list)):
                fieldnames.append(type_of_events_list[i])
                # fieldnames.append("Count")
                # fieldnames.append(f"Count ({type_of_events_list[i]})")

            # Create csv
            writer = csv.DictWriter(outfile, fieldnames=fieldnames)
            writer.writeheader()

            for i in range(len(events_history_2d[0])): # Itr through time
                row = {
                    fieldnames[0]: events_history_2d[0][i][0]
                }
                for k in range(len(type_of_events_list)):
                    curr_event = fieldnames[k + 1]
                    index_of_curr_event = type_of_events_list.index(curr_event)
                    row[curr_event] = events_history_2d[index_of_curr_event][i][1]

                writer.writerow(row)